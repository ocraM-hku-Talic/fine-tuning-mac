#!/usr/bin/env python3
"""
Script to clean Q&A data generated by DeepSeek-r1 model:
1. Removes <think>...</think> tags and thinking artifacts
2. Removes QUESTION/ANSWER formatting and numbering
3. Cleans up markdown and formatting artifacts
4. Ensures consistent data for fine-tuning
"""

import json
import re
import os

# Input and output files
input_file = "course_qa_data.jsonl"
output_file = "cleaned_course_qa_data.jsonl"

# Regular expressions for cleaning
question_pattern = re.compile(r'^(?:\*\*)?(?:QUESTION|Q)(?:\s*\d+:|\s*\d+\.)?\s*(?:\*\*)?\s*', re.IGNORECASE)
answer_pattern = re.compile(r'^(?:\*\*)?(?:ANSWER|A)(?:\s*\d+:|\s*\d+\.)?\s*(?:\*\*)?\s*', re.IGNORECASE)
marker_pattern = re.compile(r'^(?:===\s*QUESTION\s*\d+\s*===\s*|###\s*QUESTION\s*\d+:?\s*)', re.IGNORECASE)
thinking_pattern = re.compile(r'<think>.*?</think>', re.DOTALL)
thought_lines_pattern = re.compile(r'^(I should|Let me|I need|I think|I\'ll|Maybe|Wait|So|For|From|Then|But|Also)', re.IGNORECASE)
thought_reflection = re.compile(r'^(This|That|These|Those|The first|The second|The third|Another)', re.IGNORECASE)
markdown_pattern = re.compile(r'^\s*[\*\-\#]+\s+|\`\`\`.*?\`\`\`|^\s*\d+\.\s+', re.MULTILINE)
divider_pattern = re.compile(r'^\s*[\-=_]{3,}\s*$', re.MULTILINE)

def is_thinking_line(line):
    """Check if a line appears to be thinking/planning rather than content"""
    thinking_indicators = [
        "I should", "Let me", "I need to", "I think", "I'll", "Maybe", "Wait,", 
        "So ", "Actually,", "Hmm,", "Perhaps", "I'm going", "I'd", "But ", "Wait,",
        "Let's", "First,", "Second,", "Next,", "Finally,", "For example"
    ]
    return any(indicator in line for indicator in thinking_indicators)

def clean_text(text):
    """Remove question/answer markers and other formatting artifacts"""
    # Remove thinking sections if present
    text = thinking_pattern.sub('', text)
    
    # Remove markers at the beginning
    text = marker_pattern.sub('', text)
    text = question_pattern.sub('', text)
    text = answer_pattern.sub('', text)
    
    # Remove markdown formatting
    text = markdown_pattern.sub('', text)
    text = divider_pattern.sub('', text)
    
    # Remove asterisks used for bold/italic
    text = text.replace('**', '').replace('*', '')
    
    # Clean up leftover thinking artifacts
    cleaned_lines = []
    for line in text.split('\n'):
        line = line.strip()
        # Skip if appears to be thinking/planning
        if (is_thinking_line(line) or 
            '?' in line and line.endswith('.') or
            'should be' in line.lower() or
            'would be' in line.lower() or
            'could be' in line.lower() or
            'may be' in line.lower() or
            'might be' in line.lower() or 
            'need to' in line.lower() or
            line.startswith('Then ')):
            continue
            
        if line:
            cleaned_lines.append(line)
    
    # Rejoin cleaned lines
    text = ' '.join(cleaned_lines)
    
    # Trim whitespace and replace multiple spaces
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Remove source pattern if at the end
    text = re.sub(r'SOURCE\d+:\s*.*?$', '', text, flags=re.IGNORECASE)
    
    return text

# Process the file
cleaned_data = []
with open(input_file, 'r', encoding='utf-8') as f:
    line_num = 0
    for line in f:
        line_num += 1
        try:
            # Skip empty lines and comment lines
            if not line.strip() or line.strip().startswith('//'):
                continue
                
            # Parse JSON
            item = json.loads(line)
            
            # Clean prompt and completion
            item['prompt'] = clean_text(item['prompt'])
            item['completion'] = clean_text(item['completion'])
            
            # Skip items with empty prompts or completions after cleaning
            if not item['prompt'] or not item['completion']:
                print(f"Skipping line {line_num}: Empty prompt or completion after cleaning")
                continue
                
            # Skip if prompt is too similar to completion
            if item['prompt'] == item['completion']:
                print(f"Skipping line {line_num}: Prompt equals completion")
                continue
                
            # Skip if either is too short
            if len(item['prompt']) < 10 or len(item['completion']) < 10:
                print(f"Skipping line {line_num}: Text too short")
                continue
            
            # Skip if completion contains "should" or "would" or "could"
            if any(word in item['completion'].lower() for word in ["should ", "would ", "could ", "maybe", "perhaps"]):
                print(f"Skipping line {line_num}: Completion contains thinking language")
                continue
                
            cleaned_data.append(item)
            
        except json.JSONDecodeError:
            print(f"Error parsing JSON at line {line_num}, skipping")
        except KeyError:
            print(f"Missing 'prompt' or 'completion' at line {line_num}, skipping")
            
# Write the cleaned data
with open(output_file, 'w', encoding='utf-8') as f:
    for item in cleaned_data:
        f.write(json.dumps(item) + '\n')

print(f"Processed {len(cleaned_data)} valid Q&A pairs out of {line_num} total lines")
print(f"Saved cleaned data to {output_file}")

# Also create a split dataset
print("Creating train/validation/test split...")

import random
random.shuffle(cleaned_data)

# Split 70/20/10
train_size = int(0.7 * len(cleaned_data))
valid_size = int(0.2 * len(cleaned_data))

train_data = cleaned_data[:train_size]
valid_data = cleaned_data[train_size:train_size+valid_size]
test_data = cleaned_data[train_size+valid_size:]

# Create directory if it doesn't exist
os.makedirs("cleaned-dataset", exist_ok=True)

# Save split files
with open("cleaned-dataset/Train.jsonl", 'w', encoding='utf-8') as f:
    for item in train_data:
        f.write(json.dumps(item) + '\n')
        
with open("cleaned-dataset/Valid.jsonl", 'w', encoding='utf-8') as f:
    for item in valid_data:
        f.write(json.dumps(item) + '\n')
        
with open("cleaned-dataset/Test.jsonl", 'w', encoding='utf-8') as f:
    for item in test_data:
        f.write(json.dumps(item) + '\n')

print(f"Split {len(cleaned_data)} examples into:")
print(f"  - Training: cleaned-dataset/Train.jsonl ({len(train_data)} examples)")
print(f"  - Validation: cleaned-dataset/Valid.jsonl ({len(valid_data)} examples)")
print(f"  - Test: cleaned-dataset/Test.jsonl ({len(test_data)} examples)")
